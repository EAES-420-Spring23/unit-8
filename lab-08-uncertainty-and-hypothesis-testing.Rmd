---
title: "Lab 08 - Quantifying Uncertainty and Hypothesis Testing"
output: 
  tufte::tufte_html:
    css: lab.css
    tufte_variant: "envisioned"
    highlight: pygments
link-citations: yes
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(eval = TRUE)
```

# Learning goals

-   Practice bootstrapping to estimate population parameters
-   Practice testing hypotheses using randomization

## Data

```{r photo, fig.margin = TRUE, echo = FALSE, fig.width = 3, fig.cap = "Morgan Monroe State Forest", eval = TRUE}
knitr::include_graphics("img/monroe-summer.jpeg")
```

For this lab you will again be working with hourly flux data from the Morgan Monroe State Forest ecosystem flux tower, located in Indiana.
These data are generated from near-surface meteorological measurements paired with measurements of atmospheric gases including carbon dioxide and water vapour concentrations.

The data are located in your `/data` folder.
Look in the folder to check the name.

We provide a data dictionary here to give you more information on these variables.
Don't worry about the details and scientific units!
The goal of this lab is **not** to become ecosystem scientists :)

**Data Dictionary**

-   **date**: date and time
-   **fco2** : CO2 flux *positive values = net emission; negative values = net uptake*
-   **turbulence** : a measure of air turbulence, related to wind speed
-   **air_temperature** : air temperature in degrees Celcius
-   **precipitation**: rainfall in millimeters
-   **evaporation** : the energy lost via evaporation of water from the ecosystem
-   **incoming_radiation** : incoming shortwave solar radiation
-   **relative_humidity** : the percent (%) saturation of the near surface atmosphere
-   **air_pressure** : the barometric air pressure

## Packages

We will need both the `tidyverse`, `lubridate`, and the `tidymodels` packages

```{r load-packages, message = FALSE}
library(tidyverse)
library(tidymodels)
library(lubridate)
```

## Warm up

Before we start the lab, let's warm up by changing the YAML in the starter file:

-   Update the YAML, changing the author name to your name, and **knit** the document. üß∂
-   Commit your changes with a meaningful commit message. ‚úÖ
-   Push your changes to GitHub.Ô∏è ‚¨ÜÔ∏è
-   Go to your repo on GitHub and confirm that your changes are visible in your Rmd files.

# Lab Exercises

## Importing the data

1.  Look in the Lab 8 `/data` sub-directory and identify the name and file type of the dataset we need to load. Then complete the code chunk below in your starter file to load the ecosystem flux data and assign the imported data to a new object called `fluxes`.

```{r import-data}
# replace with your code
```

## Fixing the date column

Before we subset based on `date`, we need to convert the `date` column into a **date class**, otherwise R will treat it like a numerical variable.
The following code chunk is in your starter file.
Run it to fix the date column (also remove eval = F, or set it = T.)

You don't need to do anything else - just look at the code and output, and satisfy yourself that you understand why we are using the `{lubridate}` function `myd_hm()`.
If you're not sure, ask about it!

```{r fix-dates, eval = F}
fluxes <- fluxes %>% 
  mutate(date = mdy_hm(date))
head(fluxes)
```

## Filtering for a summer month, and a numerical explanatory variable of interest

2.  Copy the code chunk below into Exercise 2 in your starter file.\

-   Then, complete the pipeline so that it will subset the data for **one month in summer in 2020** (June, July or August).\

-   Then, select a numerical variable you found to be interesting in Lab 7 (or another numerical variable you find interesting).

-   Remember to change `eval` to `T` when you are ready to run the chunk.
    Note that you are creating a new data frame called `fluxes_subset` from this pipeline.

```{r subset-fluxes, eval = F}
fluxes_subset <- ___ %>% 
  filter(date > "YYYY-MM-DD" & date < "YYYY-MM-DD") %>% 
  select(date, fco2, ___)
head(fluxes_subset, 10) 
```

## Checking our dimensions

3.  Before we generate many random samples from our month of flux data. Let's double check the dimensions of our dataset.

-   Insert and label a code chunk into your starter file under Exercise 3 or use in-line code to state how many observations (rows) of data you have for the month you selected.
-   Also state what each row represents

4.  If we defined our underlying population as **summertime** `fco2` fluxes, would our sample be a good sample of that population? Explain why or why not?

## Computing our sample slope by fitting a model

5.  Insert and label a code chunk that fits a linear model between `fco2` and your chosen explanatory variable.\

-   State in text narrative under your code how we interpret the model estimate values (i.e. by much does `fco2` change with a unit increase in the explanatory variable?)
-   You can refer back to your code from lab 7 to write this answer.

## Simulating a subsample

In our case, we have all the flux data for the month you selected.
In a sense, therefore, we do roughly have a sense of the underlying "population".
More often in science, we only have a few samples from a much larger population.
So in the next exercises we will randomly sub-sample our month of data to simulate this more common scenario.

6.  Copy and complete the code chunk below that will randomize the order of the observations (rows) in your month of data, then slice (retain) only the first 20% of the data. You can manually calculate how many rows that corresponds to by referring back to your answer for Exercise 3.

-   The new data object should be called `monroe_MONTH_subsample` (insert your month's name at MONTH) and state under the chunk what each row of the code is doing.
-   Note here we are not yet generating bootstrap samples, so we use `replace  = F`.
-   Make sure you understand what this code is doing before moving on.

```{r randomoize-and-slice, eval = F}
___ <- fluxes_subset %>% 
  mutate(row = 1:n(),
         rrow = sample(row, size = n(), replace  = F)) %>% 
  arrange(rrow) %>% 
  slice_head(___)
```

## Bootstrap sampling your data

We will now step you through generating bootstrap samples.

7.  Take 1000 bootstrap samples. Call your new object `monroe_MONTH_boot`

```{r create-bootstraps, eval = F}
___ <- bootstraps(___, times = 1000)
```

8.  For each sample: fit a model and save output in model column. Tidy model output and save in coef_info column. Call your new model object `monroe_MONTH_models`.

```{r fit-models, eval = F}
___ <- ___ %>%
  mutate(
    model = map(___, ~ lm(___ ~ ___, data = .)),
    coef_info = map(model, tidy)
  )
```

9.  Copy and paste the code chunk below into your starter file, then edit it so that, for each model, it unnests (extract) the slope coefficients. Save the object as `monroe_MONTH_coef` and output the percentiles:

```{r get-slope-range, eval = F}
___ <- monroe_MONTH_models %>%
  unnest(coef_info)

int_pctl(monroe_MONTH_models, coef_info)
```

üß∂ ‚úÖ ‚¨ÜÔ∏è Knit, *commit, and push your changes to GitHub with an appropriate commit message.*

## Hypothesis testing

We might ask the question: Are warm temperatures (\> 20-degrees Celsius) more likely in June than in July?

First, we need to convert the `air_temperature` variable into a categorical variable.

10.  Copy and paste the code chunk below into your starter file under Exercise 9, and complete the `mutate()` and `case_when()` function combination to set `air_temperature` values greater than 30-degrees Celsius equal to "yes" in a new `warm_temperatures` variable, and "no" when lower than 30-degrees Celsius. Set everything else equal to `NA`. The code will also provide a new month column with either "June" or "July" as entries.

```{r create-warm-temperatures, eval = F}
temps_june_july <- fluxes %>% 
  filter(date > "2020-06-01" & date < "2020-07-31") %>% 
  mutate(warm_temperatures = case_when(
    air_temperature > ___ ~ "yes",
    air_temperature < ___ ~ "no",
    TRUE ~ NA
  ),
        month = case_when(
    date > "YYYY-MM-DD" & date < "YYYY-MM-DD" ~ "June",
    date > "YYYY-MM-DD" & date < "YYYY-MM-DD" ~ "July",
    TRUE ~ NA
  )
        ) %>% 
  select(month, air_temperature, warm_temperatures)
```

11. Let's visualize our observations for each month. Copy and paste the code chunk below into your starter and complete it so that:

-   missing values are removed in `month` and `warm_temperatures` columns
-   we fill two bars according to the count of warm vs. cool summer hours
-   after finishing your plot, state in text narrative in which month warm temperatures are more frequently observed

```{r visualize-warm-temperatures, eval = F}
temps_june_july %>% 
  filter(!is.na(___) & !is.na(___)) %>% 
  mutate(month = fct_relevel(month, "June", "July")) %>% 
  ggplot(aes(___, fill = ___)) +
  geom_bar() +
  scale_fill_manual(values = c("blue", "orange")) +
  theme_minimal() +
  labs(title = "Hours of warm or cool temperatures",
       subtitle = "In June and July",
       y = "Count",
       x = "Month",
       fill = "Temp > 20-degrees C?") +
  theme_bw()
```

Hypothesis testing using randomization allows us to ask the statistical question: is the difference in occurrence of warm temperatures between July and August due to random chance (the NULL hypothesis), OR is it due to the change in month (ALTERNATIVE hypothesis)?

First, let's calculate our sample statistic `p` for the difference in probability of warm temperatures between July and August:

```{r get-counts, eval = F}
temps_june_july %>% 
  filter(!is.na(month) & !is.na(warm_temperatures)) %>% 
  group_by(month) %>% 
  summarize(warm = sum(warm_temperatures == "yes"),
            cool = sum(warm_temperatures == "no"),
            total_hours = n())
```

12. Using the code chunk below in your starter file, insert the values from the last output to compute the sample statistic `p`.

```{r calculate-sample-p, eval = F}
p_hat <- (___/___) - (___/___) # Eqn is n_yes_july/n_all_july - n_yes_june/n_all_june
p_hat
```

From this we can say...

"From our data, warm temperatures are r p_hat*100 (wrap in backtick to run) more likely in July than in June"

Finally, we want to see whether this probability (p_hat) is an extreme value, given the data.

13. Copy and paste the code chunk below, and complete it to test the hypothesis that `warm_temperatures` is dependent on `month` in a non-random manner using 1000 bootstrap simulations. After completing the code, state below you chunk output whether you will accept or reject the null hypothesis, and why.

```{r test-temperature-hypothesis, eval = F}
set.seed(35)
temps_june_july %>%
  filter(!is.na(month) & !is.na(warm_temperatures)) %>% 
  specify(___ ~ ___, success = "yes") %>%
  hypothesize(null = "independence") %>%
  generate(reps = ___, type = "permute") %>%
  calculate(stat = "diff in props", order = c("June", "July")) %>% 
  summarize(p_value = sum(stat > ___) / n())
```

You are officially done with all the labs and homework in EAES 420!
Good job!
üëè
